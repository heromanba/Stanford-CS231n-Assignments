{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Check if gpu is available '''\n",
    "# (1):\n",
    "print(\"Method (1) stdout: \")\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# (2)\n",
    "print(\"Method (2) stdout: \")\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n",
    "    \n",
    "# (3)\n",
    "print(\"\\nMethod (3) stdout: \")\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices() \n",
    "    print(devices)\n",
    "    \n",
    "# (4)\n",
    "print(\"\\nMethod (4) stdout: \")\n",
    "from tensorflow.python.client import device_lib\n",
    "from pprint import pprint\n",
    "pprint(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d between `tf.nn.conv2d` and `tf.layers.conv2d` is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the same `input` and `weights` to test implementation.\n",
    "conv2d_input_np = np.random.normal(size=[1, 3, 3, 5])\n",
    "conv2d_filters_np = np.random.normal(size=[1, 1, 5, 1])\n",
    "\n",
    "conv2d_input = tf.constant(conv2d_input_np)\n",
    "conv2d_filters = tf.constant(conv2d_filters_np)\n",
    "\n",
    "# (1)\n",
    "# tf.nn.conv2d\n",
    "def tf_nn_conv2d(input, filters):\n",
    "    # Use function to avoid naming conflicts.\n",
    "    # tf.Variable (class): \n",
    "    #     A variable maintains state in the graph across calls to `run()`. \n",
    "    #     When you launch the graph, variables have to be explicitly \n",
    "    #     initialized before you can run Ops that uses their value.\n",
    "    input = tf.Variable(input)\n",
    "    filters = tf.Variable(filters)\n",
    "    # No `bias` added for `tf.nn.conv2d`.\n",
    "    nn_conv2d_op = tf.nn.conv2d(\n",
    "        input=input,\n",
    "        filters=filters,\n",
    "        strides=[1,1,1,1],\n",
    "        padding='VALID',\n",
    "        data_format='NHWC',\n",
    "        dilations=None,\n",
    "        name=None\n",
    "    )\n",
    "    \n",
    "    # Add an Op to initialize global variables.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        res = sess.run(nn_conv2d_op)\n",
    "    return res\n",
    "\n",
    "nn_conv2d_res = tf_nn_conv2d(conv2d_input, conv2d_filters)\n",
    "\n",
    "# (2)\n",
    "# tf.layers.conv2d\n",
    "def tf_layers_conv2d(input, filters):\n",
    "    input = tf.Variable(input)\n",
    "    \n",
    "    kernel_initializer = tf.constant_initializer(value=tf.Session().run(filters))\n",
    "    \n",
    "    # tf.layers.conv2d:\n",
    "    #     Functional interface for the 2D convolution layer.\n",
    "    # Arguments:\n",
    "    #     inputs: \n",
    "    #         Tensor input.\n",
    "    #     filters: \n",
    "    #         Integer, the dimensionality of the output space (i.e. The number \n",
    "    #         of filters in the convolution).\n",
    "    #     kernel_size: \n",
    "    #         An integer or tuple/list of 2 integers, specifying the height and \n",
    "    #         width of the 2D convolution window. Can be a single integer to specify\n",
    "    #         the same value for all spatial dimensions.\n",
    "    layers_conv2d_op = tf.layers.conv2d(\n",
    "        inputs=input, \n",
    "        filters=1, \n",
    "        kernel_size=[1,1], \n",
    "        strides=1,\n",
    "        padding='VALID', \n",
    "        use_bias=False,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        data_format=\"channels_last\"\n",
    "    )\n",
    "    \n",
    "    # Add an Op to initialize global variables.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            sess.run(init_op)\n",
    "            res = sess.run(layers_conv2d_op) \n",
    "    return res\n",
    "\n",
    "layers_conv2d_res = tf_layers_conv2d(conv2d_input, conv2d_filters)\n",
    "\n",
    "print(\n",
    "    \"conv2d between `tf.nn.conv2d` and `tf.layers.conv2d` is: \", \\\n",
    "    rel_error(nn_conv2d_res, layers_conv2d_res)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wangchu/anaconda3/envs/machine_learning/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "conv2d between tf.nn.conv2d and tf.keras.layers.Conv2d is:  0.0\n",
      "conv2d between tf.layers.conv2d and tf.keras.layers.Conv2d is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# (3)\n",
    "# tf.keras.layers\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "# Use the same `input` and `weights` to test implementation.\n",
    "# To avoid `Tensor is not an element in the graph` error.\n",
    "conv2d_input = tf.constant(conv2d_input_np)\n",
    "conv2d_filters = tf.constant(conv2d_filters_np)\n",
    "\n",
    "\n",
    "def tf_keras_conv2d(input, filters):\n",
    "    # tf.keras.Input:\n",
    "    #     Used to instantiate a Keras tensor.\n",
    "    # Arguments:\n",
    "    #     shape:\n",
    "    #         A shape tuple (integers), not including the batch size. For instance,\n",
    "    #         `shape=(32,)` indicates that the expected input will be batches of \n",
    "    #         32-dimensional vectors. Elements of this tuple can be None; `None`\n",
    "    #         elements represent dimensions where the shape is not known.\n",
    "    #     tensor:\n",
    "    #         Optional existing tensor to wrap into the Input layer. If set, the layer\n",
    "    #         will not create a placeholder tensor.\n",
    "    input = tf.keras.Input(\n",
    "        shape=input.get_shape().as_list(),\n",
    "        tensor=input\n",
    "    )\n",
    "    \n",
    "    kernel_initializer = tf.constant_initializer(value=tf.Session().run(filters))\n",
    "    \n",
    "    # tf.keras.layers.Conv2D:\n",
    "    #     This layer creates a convolution kernel that is convolved with the layer \n",
    "    #     input to produce a `tensor` of outputs.\n",
    "    # Arguments:\n",
    "    #     filters: \n",
    "    #         Integer, the dimensionality of the output space (i.e. The number \n",
    "    #         of filters in the convolution).\n",
    "    #     kernel_size: \n",
    "    #         An integer or tuple/list of 2 integers, specifying the height and \n",
    "    #         width of the 2D convolution window. Can be a single integer to specify\n",
    "    #         the same value for all spatial dimensions.\n",
    "    keras_conv2d = tf.keras.layers.Conv2D(\n",
    "        filters=1, \n",
    "        kernel_size=[1,1], \n",
    "        strides=1,\n",
    "        padding='VALID', \n",
    "        use_bias=False,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        data_format=\"channels_last\"\n",
    "    )(input)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input, outputs=keras_conv2d)\n",
    "    # model.summary()\n",
    "    \n",
    "    # Add an Op to initialize global variables.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        res = sess.run(model(input, training=False))\n",
    "    return res\n",
    "\n",
    "keras_conv2d_res = tf_keras_conv2d(conv2d_input, conv2d_filters)\n",
    "\n",
    "print(\n",
    "    \"conv2d between tf.nn.conv2d and tf.keras.layers.Conv2d is: \", \\\n",
    "    rel_error(nn_conv2d_res, keras_conv2d_res)\n",
    ")\n",
    "print(\n",
    "    \"conv2d between tf.layers.conv2d and tf.keras.layers.Conv2d is: \", \\\n",
    "    rel_error(layers_conv2d_res, keras_conv2d_res)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.contrib.slim' from '/home/wangchu/anaconda3/envs/machine_learning/lib/python3.6/site-packages/tensorflow_core/contrib/slim/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4)\n",
    "# tf.slim.conv2d\n",
    "tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Normalization\n",
    "![](batch_norm_cs231n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Without Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.ops import math_ops, nn_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8294014e-06\n",
      "1.4568574e-06\n",
      "4.8294014e-06\n"
     ]
    }
   ],
   "source": [
    "x_shape = [3, 5, 4, 2]    # NHWC\n",
    "param_shape = [2]    # C\n",
    "x_val = np.random.random_sample(x_shape).astype(np.float32)\n",
    "m_val = np.random.random_sample(param_shape).astype(np.float32)\n",
    "v_val = np.random.random_sample(param_shape).astype(np.float32)\n",
    "beta_val = np.random.random_sample(param_shape).astype(np.float32)\n",
    "gamma_val = np.random.random_sample(param_shape).astype(np.float32)\n",
    "epsilon = 1e-8\n",
    "\n",
    "# (1)\n",
    "# low level ops\n",
    "\n",
    "# https://github.com/tensorflow/tensorflow/blob/50396e0d8e7c6bf518d4eff28766c872ebd6f3d9/tensorflow/python/ops/nn_batchnorm_test.py\n",
    "def _npBatchNorm(x, m, v, beta, gamma, epsilon,\n",
    "                scale_after_normalization, shift_after_normalization):\n",
    "    y = (x - m) / np.sqrt(v + epsilon)\n",
    "    if scale_after_normalization:\n",
    "        y = y * gamma\n",
    "    if shift_after_normalization:\n",
    "        y = y + beta\n",
    "    return y\n",
    "\n",
    "def _opsBatchNorm(x, m, v, beta, gamma, epsilon,\n",
    "                 scale_after_normalization, shift_after_normalization):\n",
    "    y = (x - m) * math_ops.rsqrt(v + epsilon)\n",
    "    if scale_after_normalization:\n",
    "        y = gamma * y\n",
    "    if shift_after_normalization:\n",
    "        y = y + beta\n",
    "    return y\n",
    "\n",
    "def _tfBatchNormV2(x, m, v, beta, gamma, epsilon,\n",
    "                  scale_after_normalization, shift_after_normalization):\n",
    "    \"\"\"New implementation.\"\"\"\n",
    "    return nn_impl.batch_normalization(x, m, v, beta if\n",
    "                                       shift_after_normalization else None,\n",
    "                                       gamma if scale_after_normalization else\n",
    "                                       None, epsilon)\n",
    "\n",
    "def testBatchNorm(x_val, m_val, v_val, beta_val, gamma_val, epsilon):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        x = constant_op.constant(x_val, name='x')\n",
    "        m = constant_op.constant(m_val, name='m')\n",
    "        v = constant_op.constant(v_val, name='v')\n",
    "        beta = constant_op.constant(beta_val, name='beta')\n",
    "        gamma = constant_op.constant(gamma_val, name='gamma')\n",
    "        \n",
    "        scale_after_normalization = True\n",
    "        shift_after_normalization = True\n",
    "        \n",
    "        bn2 = _tfBatchNormV2(x, m, v, beta, gamma, epsilon,\n",
    "                             scale_after_normalization,\n",
    "                             shift_after_normalization)\n",
    "        \n",
    "        on = _opsBatchNorm(x, m, v, beta, gamma, epsilon,\n",
    "                          scale_after_normalization,\n",
    "                          shift_after_normalization)\n",
    "        \n",
    "        np_bn = _npBatchNorm(x_val, m_val, v_val, beta_val, gamma_val,\n",
    "                             epsilon, scale_after_normalization,\n",
    "                             shift_after_normalization)\n",
    "        \n",
    "        tf_bn_v2, ops_bn = sess.run([bn2, on])\n",
    "        \n",
    "        print(rel_error(np_bn, ops_bn))\n",
    "        print(rel_error(np_bn, tf_bn_v2))\n",
    "        print(rel_error(tf_bn_v2, ops_bn))\n",
    "        return np_bn, ops_bn, tf_bn_v2\n",
    "\n",
    "np_bn, ops_bn, tf_bn_v2 = testBatchNorm(x_val, m_val, v_val, beta_val, gamma_val, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4568574e-06\n",
      "0.0\n",
      "4.8294014e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (2)\n",
    "# tf.nn.batch_normalization\n",
    "\n",
    "# https://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "def tf_nn_batch_norm(x_val, m_val, v_val, beta_val, gamma_val, epsilon):\n",
    "    x = constant_op.constant(x_val, name='x')\n",
    "    \n",
    "    mean = tf.Variable(tf.constant(m_val), trainable=False)\n",
    "    variance = tf.Variable(tf.constant(v_val), trainable=False)\n",
    "    \n",
    "    beta = tf.Variable(tf.constant(beta_val))\n",
    "    gamma = tf.Variable(tf.constant(gamma_val))\n",
    "           \n",
    "    # Add an Op to initialize global variables.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        tf_nn_batch_norm_op = tf.nn.batch_norm_with_global_normalization(\n",
    "            x, mean, variance, beta, gamma, epsilon, True)\n",
    "        res = sess.run(tf_nn_batch_norm_op)\n",
    "    return res\n",
    "    \n",
    "tf_nn_bn = tf_nn_batch_norm(x_val, m_val, v_val, beta_val, gamma_val, epsilon)\n",
    "\n",
    "# Note: no moving average is applied.\n",
    "print(rel_error(tf_nn_bn, np_bn))\n",
    "print(rel_error(tf_nn_bn, tf_bn_v2))\n",
    "print(rel_error(tf_nn_bn, ops_bn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 With Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c4cef034232a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Returns:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#     Two `Tensor` objects: `mean` and `variance`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mma_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mewma_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# tf.train.ExponentialMovingAverage (class):\n",
    "#     Maintains moving averages of variables by employing an exponential decay.\n",
    "#     The `apply()` method adds shadow copies of trained variables and add ops that \n",
    "#     maintain a moving average of the trained variables in their shadow copies. It\n",
    "#     is used when building the training model. The ops that maintain moving averages\n",
    "#     are typically run after each training step. The `average()` and `average_name()`\n",
    "#     methods give access to the shadow variables and their names.\n",
    "# Args:\n",
    "#     decay: \n",
    "#         Float. The decay to use.\n",
    "# Methods:\n",
    "#     apply(var_list=None):\n",
    "#         Maintains moving averages of variables.\n",
    "#         Args:\n",
    "#             var_list:\n",
    "#                 A list of Variable or Tensor objects. The variables and Tensors must\n",
    "#                 be of type float16, float32, or float64.\n",
    "#         Returns:\n",
    "#             An Operation that updates the moving averages.\n",
    "#     average(var):\n",
    "#         Returns the `Variable` holding the average of `var`.\n",
    "#         Args:\n",
    "#             var:\n",
    "#                 A `Variable` object.   \n",
    "#         Returns:\n",
    "#             A `Variable` object or `None` if the moving average of `var` is not maintained.\n",
    "ewma_trainer = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "\n",
    "# tf.nn.moments:\n",
    "#     Calculates the mean and variance of `x`. The mean and variance are calculated\n",
    "#     by aggregating the contents of `x` across `axes`. If `x` is 1-D and `axes=[0]`\n",
    "#     this is just the mean and variance of a vector.\n",
    "#     When using these moments for batch normalization (tf.nn.batch_normalization):\n",
    "#         - for so-called \"global normalization\", used with convolutional filters\n",
    "#           with shape `[batch, height, width, depth]`, pass `axes=[0, 1, 2]`.\n",
    "#         - for simple batch normalization pass `axes=[0]` (batch only).\n",
    "# Args:\n",
    "#     `x`: A `Tensor`\n",
    "#     `axes`: Array of ints. Axes along which to compute mean and variance.\n",
    "# Returns:\n",
    "#     Two `Tensor` objects: `mean` and `variance`.\n",
    "ma_mean, ma_variance = tf.nn.moments(x, [0, 1, 2])\n",
    "\n",
    "ewma_trainer.apply([self.mean, self.variance])\n",
    "\n",
    "\n",
    "# tf.Variable (class)\n",
    "# Methods:\n",
    "#     assign(value):\n",
    "#     Assigns a new value to the variable. This is essentially a shortcut for `tf.assign`.\n",
    "\n",
    "\n",
    "# tf.assign(ref, value):\n",
    "#     This operation outputs a Tensor that holds the new value of `ref` after the value\n",
    "#     has been assigned. This makes it easier to chain operations that need to use the \n",
    "#     reset value.\n",
    "# Args:\n",
    "#     `ref`: \n",
    "#         A mutable `Tensor`. Should be from a `Variable` node. May be uninitialized.\n",
    "#     `value`:\n",
    "#         A `Tensor`. Must have the same shape and dtypes as `ref`. The value to be\n",
    "#         assigned to the variable.\n",
    "# Returns:\n",
    "#     A `Tensor` that will hold the new value of `ref` after the assignment has completed.\n",
    "assign_mean = mean.assign(ma_mean)\n",
    "assign_variance = variance.assign(ma_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
